{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa60e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas ## 2.2\n",
    "#!pip install matplotlib   ## 3.10\n",
    "#!pip install scikit-learn ## 1.6\n",
    "\n",
    "#!pip install tensorflow          ## 2.17\n",
    "#!pip install 'tensorflow[gpu]'   ## 2.17\n",
    "#!pip install tensorflow-datasets ## 4.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "135df1f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\Users\\Angel Temporal\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 70, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: Error en una rutina de inicialización de biblioteca de vínculos dinámicos (DLL).\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:70\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 70\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tensorflow_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _pywrap_tensorflow_internal: Error en una rutina de inicialización de biblioteca de vínculos dinámicos (DLL).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \u001b[38;5;66;03m# 1.26\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m \u001b[38;5;66;03m# 2.17\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfds\u001b[39;00m \u001b[38;5;66;03m# 4.9\u001b[39;00m\n\u001b[0;32m      9\u001b[0m np\u001b[38;5;241m.\u001b[39m__version__, tf\u001b[38;5;241m.\u001b[39m__version__, tfds\u001b[38;5;241m.\u001b[39m__version__\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\__init__.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m _os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:85\u001b[0m\n\u001b[0;32m     83\u001b[0m     sys\u001b[38;5;241m.\u001b[39msetdlopenflags(_default_dlopen_flags)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     86\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;241m.\u001b[39mformat_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     87\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     88\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee https://www.tensorflow.org/install/errors \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     89\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfor some common causes and solutions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     90\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you need help, create an issue \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     91\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat https://github.com/tensorflow/tensorflow/issues \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     92\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand include the entire stack trace above this error message.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"C:\\Users\\Angel Temporal\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 70, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: Error en una rutina de inicialización de biblioteca de vínculos dinámicos (DLL).\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np # 1.26\n",
    "import tensorflow as tf # 2.17\n",
    "import tensorflow_datasets as tfds # 4.9\n",
    "\n",
    "np.__version__, tf.__version__, tfds.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049c0fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.layers import Conv2D, Flatten, MaxPooling2D\n",
    "from keras.optimizers import Adagrad, Adam, AdamW, Adamax, RMSprop, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ba018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "entrada = Input(shape=(4,))\n",
    "layer1 = Dense(units=3, activation='relu') # oculta\n",
    "layer2 = Dense(units=4, activation='relu') # oculta\n",
    "salida = Dense(units=1, activation='relu')\n",
    "\n",
    "red1 = Sequential( [entrada,layer1,layer2,salida] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879fa86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "red2 = Sequential()\n",
    "red2.add(entrada)\n",
    "red2.add(layer1)\n",
    "red2.add(layer2)\n",
    "red2.add(salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38767b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # 2.2.3\n",
    "import matplotlib.pyplot as plt # 3.10.0\n",
    "from sklearn.preprocessing import MinMaxScaler # 1.6.1\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff55dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('boston_house_price.csv')\n",
    "cols_name = df.columns\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6350a98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5f994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934c1dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['MEDV'])\n",
    "y = df['MEDV']\n",
    "n_cols = X.shape[1]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc6fd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=cols_name[:-1])\n",
    "X.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3597cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f187bac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=23)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925d7026",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ntrada = Input(shape=(n_cols,))\n",
    "salida = Dense(units=1, activation='linear')\n",
    "\n",
    "### A) instancia de la técnica -> modelo\n",
    "red3 = Sequential([ntrada,salida])\n",
    "red3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dca0c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2_250\n",
    "batch_size = 10\n",
    "learn_rate = .002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dd1151",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizador = Adam(learning_rate=learn_rate)\n",
    "red3.compile(loss=\"mae\", optimizer=optimizador, metrics=[\"mse\"])\n",
    "\n",
    "### B) Ajustar Parámetros del Modelo a la Data\n",
    "with tf.device('/GPU:0'):\n",
    "    summary = red3.fit(X_train, y_train, batch_size=batch_size,\n",
    "        epochs=n_epochs, validation_split=0.2, verbose=0)\n",
    "\n",
    "summary.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0b6541",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_skip = 100\n",
    "plt.plot(summary.history['mse'][n_skip:], c='b')\n",
    "plt.plot(summary.history['val_mse'][n_skip:], c='g')\n",
    "\n",
    "plt.legend(['Train','Valid'], loc='upper right')\n",
    "plt.title('Training History')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dec5732",
   "metadata": {},
   "outputs": [],
   "source": [
    "### C) Predicción\n",
    "y_pred = red3.predict(X_test)[:,0]\n",
    "### D) Test/Prueba del rendimiento del modelo\n",
    "RMSE1 = np.sqrt(np.mean((y_test-y_pred)**2))\n",
    "np.round(RMSE1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a690b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = red3.evaluate(X_test, y_test, verbose=0)[1]\n",
    "RMSE2 = np.sqrt(MSE)\n",
    "np.round(RMSE2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56c4cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "832ec6f8",
   "metadata": {},
   "source": [
    "#\n",
    "#\n",
    "___\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1ceba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # 2.2.3\n",
    "import matplotlib.pyplot as plt # 3.10.0\n",
    "from sklearn.preprocessing import MinMaxScaler # 1.6.1\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b6287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = load_iris()\n",
    "X = data_raw['data']\n",
    "y0= data_raw['target'].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3310da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['SepalLenght', 'SepalWidth','PetalLenght', 'PetalWidth',\n",
    "      'Setosa', 'Virginica', 'Versicolor']\n",
    "y = tf.keras.utils.to_categorical(y0, num_classes=3)\n",
    "df = pd.DataFrame(np.concatenate([X,y],axis=1),columns=header)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159705a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,y, test_size=0.2, random_state=123)\n",
    "n_vars = X_train.shape[1]\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8be618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrada = Input(shape=(n_vars,))\n",
    "salida = Dense(units=3, activation='softmax')\n",
    "\n",
    "### A) instancia de la técnica -> modelo\n",
    "red4 = Sequential([ntrada,salida])\n",
    "red4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84403e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1100\n",
    "batch_size = 10\n",
    "learn_rate = .005\n",
    "\n",
    "optimizador = Adam(learning_rate=learn_rate)\n",
    "red4.compile(loss=\"categorical_crossentropy\",\n",
    "     optimizer=optimizador, metrics=[\"accuracy\"])\n",
    "\n",
    "### B) Ajustar Parámetros del Modelo a la Data\n",
    "with tf.device('/GPU:0'):\n",
    "    summary = red4.fit(X_train, y_train, batch_size=batch_size,\n",
    "        epochs=n_epochs, validation_split=0.2, verbose=0)\n",
    "\n",
    "summary.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7af297",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_skip = 10\n",
    "plt.plot(summary.history['accuracy'][n_skip:], c='b')\n",
    "plt.plot(summary.history['val_accuracy'][n_skip:], c='g')\n",
    "\n",
    "plt.legend(['Train','Valid'], loc='upper right')\n",
    "plt.title('Training History')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c35f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Acc = red4.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(f'Test Accuracy: {np.round(Acc,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f722cb",
   "metadata": {},
   "source": [
    "#\n",
    "___\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa314cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrada = Input(shape=(n_vars,))\n",
    "layer1 = Dense(units=6, activation='leaky_relu')\n",
    "salida = Dense(units=3, activation='softmax')\n",
    "\n",
    "### A) instancia de la técnica -> modelo\n",
    "red5 = Sequential([ntrada,layer1,salida])\n",
    "red5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2979230",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizador = Adam(learning_rate=learn_rate)\n",
    "red5.compile(loss=\"categorical_crossentropy\",\n",
    "     optimizer=optimizador, metrics=[\"accuracy\"])\n",
    "\n",
    "### B) Ajustar Parámetros del Modelo a la Data\n",
    "with tf.device('/GPU:0'):\n",
    "    summary = red5.fit(X_train, y_train, batch_size=batch_size,\n",
    "        epochs=n_epochs, validation_split=0.2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eec5bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_skip = 10\n",
    "plt.plot(summary.history['accuracy'][n_skip:], c='b')\n",
    "plt.plot(summary.history['val_accuracy'][n_skip:], c='g')\n",
    "\n",
    "plt.legend(['Train','Valid'], loc='upper right')\n",
    "plt.title('Training History')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50e4fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Acc = red5.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(f'Test Accuracy: {np.round(Acc,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d56024",
   "metadata": {},
   "source": [
    "#\n",
    "#\n",
    "___\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c46e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # 3.10.0\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbf9fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img0 = X_train[0,:,:]\n",
    "print(img0.shape)\n",
    "plt.imshow(img0, cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38618f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "fimg = img0.flatten()\n",
    "print( fimg.shape )\n",
    "df = pd.DataFrame(fimg)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11de2ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255.\n",
    "X_test  = X_test /255.\n",
    "n_train_size = X_train.shape[0]\n",
    "n_train_size, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6877ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate([y_train,y_test], axis=0)\n",
    "y = tf.keras.utils.to_categorical(y,10)\n",
    "y_train = y[:n_train_size,:]\n",
    "y_test  = y[n_train_size:,:]\n",
    "y_test.shape, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0d8669",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_prob = 0.5\n",
    "\n",
    "### A) instancia de la técnica -> modelo\n",
    "red7 = Sequential()\n",
    "# Input layer.\n",
    "red7.add(Input(shape=(28,28,1)))\n",
    "# 1st convolution + pooling.\n",
    "red7.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation=\"relu\"))\n",
    "red7.add(MaxPooling2D(pool_size=2))\n",
    "# 2nd convolution + pooling.\n",
    "red7.add(Conv2D(filters=64, kernel_size=(5,5), padding='same', activation=\"relu\"))\n",
    "red7.add(MaxPooling2D(pool_size=2))\n",
    "#Flattened fully connected layer.\n",
    "red7.add(Flatten())\n",
    "red7.add(Dense(units=1024, activation=\"relu\"))\n",
    "# Apply dropout.\n",
    "red7.add(Dropout(rate=drop_prob))\n",
    "# Output layer.\n",
    "red7.add(Dense(units=10, activation=\"softmax\"))\n",
    "\n",
    "red7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3602441d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 12\n",
    "batch_size = 200\n",
    "learn_rate = .001\n",
    "\n",
    "optimizador = Adam(learning_rate=learn_rate)\n",
    "red7.compile(loss=\"categorical_crossentropy\",\n",
    "     optimizer=optimizador, metrics=[\"accuracy\"])\n",
    "\n",
    "### B) Ajustar Parámetros del Modelo a la Data\n",
    "with tf.device('/GPU:0'):\n",
    "    summary = red7.fit(X_train, y_train, batch_size=batch_size,\n",
    "        epochs=n_epochs, validation_split=0.2, verbose=0)\n",
    "\n",
    "summary.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed142e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_skip = 0\n",
    "plt.plot(summary.history['accuracy'][n_skip:], c='b')\n",
    "plt.plot(summary.history['val_accuracy'][n_skip:], c='g')\n",
    "\n",
    "plt.legend(['Train','Valid'], loc='upper right')\n",
    "plt.title('Training History')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23562cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Acc = red7.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(f'Test Accuracy: {np.round(Acc,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9a438e",
   "metadata": {},
   "source": [
    "#\n",
    "___\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fb276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # 3.10.0\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dcc75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img0 = X_train[123,:,:]\n",
    "print(img0.shape)\n",
    "plt.imshow(img0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14258ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255.\n",
    "X_test  = X_test /255.\n",
    "n_train_size = X_train.shape[0]\n",
    "\n",
    "X_train = X_train.reshape(-1,32,32,3) # 3 canales, c/kernel * matriz de 3*3\n",
    "X_test  = X_test .reshape(-1,32,32,3)\n",
    "\n",
    "n_train_size, X_test.shape, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce97273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate([y_train,y_test], axis=0)\n",
    "y = tf.keras.utils.to_categorical(y,10)\n",
    "y_train = y[:n_train_size,:]\n",
    "y_test  = y[n_train_size:,:]\n",
    "y_test.shape, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d637d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_prob = 0.7\n",
    "\n",
    "### A) instancia de la técnica -> modelo\n",
    "red8 = Sequential()\n",
    "# Input layer.\n",
    "red8.add(Input(shape=img0.shape)) # (32,32,3)\n",
    "# 1st convolution + pooling.\n",
    "red8.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation=\"relu\"))\n",
    "red8.add(MaxPooling2D(pool_size=2))\n",
    "# 2nd convolution + pooling.\n",
    "red8.add(Conv2D(filters=64, kernel_size=(5,5), padding='same', activation=\"relu\"))\n",
    "red8.add(MaxPooling2D(pool_size=2))\n",
    "#Flattened fully connected layer.\n",
    "red8.add(Flatten())\n",
    "red8.add(Dense(units=1024, activation=\"relu\"))\n",
    "# Apply dropout.\n",
    "red8.add(Dropout(rate=drop_prob))\n",
    "# Output layer.\n",
    "red8.add(Dense(units=10, activation=\"softmax\"))\n",
    "\n",
    "red8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3e66ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 20\n",
    "learn_rate = .0001\n",
    "\n",
    "optimizador = Adam(learning_rate=learn_rate)\n",
    "red8.compile(loss=\"categorical_crossentropy\",\n",
    "     optimizer=optimizador, metrics=[\"accuracy\"])\n",
    "\n",
    "### B) Ajustar Parámetros del Modelo a la Data\n",
    "with tf.device('/GPU:0'):\n",
    "    summary = red8.fit(X_train, y_train, batch_size=batch_size,\n",
    "        epochs=n_epochs, validation_split=0.2, verbose=0)\n",
    "\n",
    "summary.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc7ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_skip = 0\n",
    "plt.plot(summary.history['accuracy'][n_skip:], c='b')\n",
    "plt.plot(summary.history['val_accuracy'][n_skip:], c='g')\n",
    "\n",
    "plt.legend(['Train','Valid'], loc='upper right')\n",
    "plt.title('Training History')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c48856",
   "metadata": {},
   "outputs": [],
   "source": [
    "Acc = red8.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(f'Test Accuracy: {np.round(Acc,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc956fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee368a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e980b1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 1\n",
    "n_neuron = 100\n",
    "n_output = 1\n",
    "\n",
    "red9 = Sequential()\n",
    "red9.add( SimpleRNN() )\n",
    "\n",
    "optimizador = Adam(learning_rate=learn_rate)\n",
    "red9.compile(loss=\"categorical_crossentropy\",\n",
    "     optimizer=optimizador, metrics=[\"accuracy\"])\n",
    "\n",
    "### B) Ajustar Parámetros del Modelo a la Data\n",
    "with tf.device('/GPU:0'):\n",
    "    summary = red9.fit(X_train, y_train, batch_size=batch_size,\n",
    "        epochs=n_epochs, validation_split=0.2, verbose=0)\n",
    "\n",
    "summary.history.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
